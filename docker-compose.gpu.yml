# GPU-optimized Docker Compose configuration
# Use this file for GPU-accelerated deployments (Requirement 6.1)
# 
# Usage:
#   docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up meeting-video-tool-gpu
#
# Prerequisites:
#   - NVIDIA Docker runtime installed
#   - NVIDIA GPU with CUDA support
#   - nvidia-container-toolkit configured

version: '3.8'

services:
  # Override CPU service to disable it in GPU mode
  meeting-video-tool-cpu:
    profiles:
      - cpu-only

  # Enhanced GPU service configuration (Requirement 6.1)
  meeting-video-tool-gpu:
    profiles:
      - gpu
      - default
    
    # GPU-specific build arguments (Requirement 6.2)
    build:
      args:
        PYTORCH_INDEX_URL: https://download.pytorch.org/whl/cu121
        ENABLE_GPU: true
    
    # Enhanced GPU environment configuration (Requirements 6.1, 6.3, 6.5)
    environment:
      # GPU detection and validation (Requirement 6.5)
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      
      # CUDA memory management
      - CUDA_LAUNCH_BLOCKING=0
      - CUDA_CACHE_DISABLE=0
      
      # PyTorch GPU optimization
      - TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6"
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    
    # GPU resource allocation with higher limits (Requirement 6.1)
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
          memory: 8G
          cpus: '4.0'
    
    # GPU runtime configuration
    runtime: nvidia
    
    # Additional GPU-specific labels for monitoring
    labels:
      - "com.meeting-video-tool.gpu=enabled"
      - "com.meeting-video-tool.cuda=12.1"