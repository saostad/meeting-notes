# Copy this file and add your actual API key
GEMINI_API_KEY=xxxxxxxxxxxxxxxxxxxxxx

# Performance settings - using smaller model for faster testing
WHISPER_MODEL=openai/whisper-large-v3-turbo
SKIP_EXISTING=true
OVERLAY_CHAPTER_TITLES=true

# AI Provider Configuration
AI_PROVIDER=local
ENABLE_FALLBACK=false
LOCAL_MODEL_NAME=phi4:latest
LOCAL_MODEL_FRAMEWORK=ollama
OLLAMA_BASE_URL=http://localhost:11434
MODEL_PARAMETERS={"num_ctx": 16384, "temperature": 0.0, "top_p": 0.1, "repeat_penalty": 1.2}

SKIP_DEPENDENCY_VALIDATION=true