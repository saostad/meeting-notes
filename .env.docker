# Docker-specific environment configuration
# This file contains optimized settings for Docker deployment

# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================

# Gemini API Key (REQUIRED)
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_api_key_here

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Gemini model for chapter analysis
GEMINI_MODEL=gemini-flash-latest

# Whisper model for transcription
# Options: base (fast), medium (balanced), large-v3-turbo (accurate)
WHISPER_MODEL=openai/whisper-large-v3-turbo

# =============================================================================
# DOCKER-OPTIMIZED SETTINGS
# =============================================================================

# Output directory (container path)
OUTPUT_DIR=/output

# Skip existing files for efficient batch processing
SKIP_EXISTING=true

# Video overlay configuration
OVERLAY_CHAPTER_TITLES=false

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# GPU configuration (for multi-GPU systems)
CUDA_VISIBLE_DEVICES=0

# PyTorch memory management
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024

# Model caching directories (container paths)
HF_HOME=/cache/huggingface
TRANSFORMERS_CACHE=/cache/huggingface
HF_DATASETS_CACHE=/cache/huggingface/datasets
TORCH_HOME=/cache/models

# =============================================================================
# LOGGING AND DEBUGGING
# =============================================================================

# Log level for debugging (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable verbose output for troubleshooting
VERBOSE=false